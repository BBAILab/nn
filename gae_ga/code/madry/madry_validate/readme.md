# Validation of Madry et al. Adversarial Examples

This folder contains programs and files for computing the percentage of adversarial examples generated by the Madry et al. method are properly classified by the originating neural network.  That is the percentage of adversarial examples that are not classified differently than their associated MNIST image.

1. Train model with natural MNIST images: train_nat_jrb.py
2. Create adversarial examples: pgd_Attack_train_jrb.py
3. Evaluate percentage of adversarial examples recognized by the network
  a. run_attack_jrb.py (changed number of permitted adversarial examples to 60000 from 10000 from run_attack.py) (from Madry)
  b. madry_train_adv_eg_predict_jrb2-1b.py
    1. Need to create text file of Madry adversarial examples using make_csv_adv_eg.py